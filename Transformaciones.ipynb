{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_csv_files_in_directory(directorio,outputs):\n",
    "    for directorio, archivo_salida in zip(directorio, outputs):\n",
    "        dfs = []\n",
    "        for filename in os.listdir(directorio):\n",
    "            # Verifica que sean archivos CSV\n",
    "            if filename.endswith('.csv'):\n",
    "                filepath = os.path.join(directorio, filename)\n",
    "                df = pd.read_csv(filepath)\n",
    "                dfs.append(df)\n",
    "        merged_df = dfs[0]\n",
    "        \n",
    "        for df in dfs[1:]:\n",
    "            merged_df = pd.merge(merged_df, df, on=['ID_RIO', 'coord_TRAMO'], how='inner')\n",
    "        \n",
    "        print(merged_df)\n",
    "        print(\"Ahora guardamos en local\")\n",
    "        merged_df.to_csv(archivo_salida, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def verificar_permisos_directorio(directory):\n",
    "    # Verificar si el directorio existe\n",
    "    if not os.path.exists(directory):\n",
    "        print(f\"El directorio {directory} no existe.\")\n",
    "        return False\n",
    "    \n",
    "    # Verificar permisos de lectura\n",
    "    if not os.access(directory, os.R_OK):\n",
    "        print(f\"No tienes permisos de lectura para el directorio {directory}.\")\n",
    "        return False\n",
    "    \n",
    "    # Verificar permisos de escritura\n",
    "    if not os.access(directory, os.W_OK):\n",
    "        print(f\"No tienes permisos de escritura para el directorio {directory}.\")\n",
    "        return False\n",
    "    \n",
    "    # Verificar permisos de ejecución\n",
    "    if not os.access(directory, os.X_OK):\n",
    "        print(f\"No tienes permisos de ejecución para el directorio {directory}.\")\n",
    "        return False\n",
    "    \n",
    "    print(f\"Tienes permisos completos para acceder al directorio {directory}.\")\n",
    "    return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from shapely.wkt import loads\n",
    "from shapely.geometry import LineString\n",
    "import geopandas as gpd\n",
    "import time\n",
    "\n",
    "def calcular_distancias(fich_rios, contaminante_sf, fich_output, contaminante_col):\n",
    "    for idx, rio in fich_rios.iterrows():\n",
    "        linestring = rio['WKT']\n",
    "        geometry = loads(linestring)\n",
    "        \n",
    "        for part in geometry.geoms:\n",
    "            #Se reducen el número de tramos a 3\n",
    "            coords = list(part.coords)\n",
    "            coordinates_to_check = [coords[0], coords[len(coords)//2] if len(coords) % 2 != 0 else coords[len(coords)//2 - 1], coords[-1]]\n",
    "            #print(\"Coordinates to check:\",coordinates_to_check)\n",
    "            #print(f\"Número de tramos del rio simplificados: {len(coordinates_to_check)}\")\n",
    "            for coordinate in coordinates_to_check:\n",
    "                #print(\"Calculando el sensor más cercano al punto: \",coordinate)\n",
    "                distances = []\n",
    "                for idx, row in contaminante_sf.iterrows():\n",
    "                    sensor = row.geometry.coords[0]  # Obtenemos las coordenadas del sensor\n",
    "                    distance = np.sqrt((coordinate[0] - sensor[0]) ** 2 + (coordinate[1] - sensor[1]) ** 2)\n",
    "                    distances.append(distance)\n",
    "\n",
    "                min_distance = min(distances)\n",
    "                min_distance_index = distances.index(min_distance)\n",
    "                closest_sensor = contaminante_sf.iloc[min_distance_index]\n",
    "\n",
    "                # Crear un DataFrame con los datos\n",
    "                data = {\n",
    "                    'ID_RIO': [rio['PFAFRIO']],\n",
    "                    'coord_TRAMO': [coordinate],\n",
    "                    f'valor_{contaminante_col}': [closest_sensor['PromedioDe']]\n",
    "                }\n",
    "                info_tramo = pd.DataFrame(data)\n",
    "\n",
    "                # Agregar datos al archivo CSV y Verificar si el archivo existe\n",
    "                if os.path.exists(fich_output):\n",
    "                    header = False\n",
    "                else:\n",
    "                    header = True\n",
    "\n",
    "                # Escribir datos en el archivo CSV\n",
    "                info_tramo.to_csv(fich_output, mode='a', header=header, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_rios_A = pd.read_csv(\"/Users/silviadelatorre/Desktop/TFG/FICHEROS INPUT/RiosAtlantico.csv\")\n",
    "print(f'Numero de rios Atlantico: {df_rios_A.shape[0]}')\n",
    "df_rios_M = pd.read_csv(\"/Users/silviadelatorre/Desktop/TFG/FICHEROS INPUT/RiosMediterraneo.csv\")\n",
    "print(f'Numero de rios Mediterraneo: {df_rios_M.shape[0]}')\n",
    "# df_rios_A_gdf = gpd.GeoDataFrame(df_rios_A, geometry=gpd.GeoSeries.from_wkt(df_rios_A['WKT']))\n",
    "# df_fitobentos = pd.read_csv(\"/Users/silviadelatorre/Desktop/TFG/AGENTES CONTAMINANTES/Fitobentos.csv\")\n",
    "# fitobentos_gdf = gpd.GeoDataFrame(df_fitobentos, geometry=gpd.GeoSeries.from_wkt(df_fitobentos['WKT']))\n",
    "# output_folder_a = \"/Users/silviadelatorre/Desktop/TFG/PFG/Results/VALORES CONTAMINACION/ATLANTICO\"\n",
    "# output_path = os.path.join(output_folder_a, \"Fitobentos.csv\")\n",
    "# calcular_distancias(df_rios_A_gdf, fitobentos_gdf,output_path,\"Fitobentos\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# UNIR TABLAS EN UNA SOLA\n",
    "# Directorios de vertientes\n",
    "vertientes_directorios = ['/Users/silviadelatorre/Desktop/TFG/PFG/Results/VALORES CONTAMINACION/ATLANTICO', '/Users/silviadelatorre/Desktop/TFG/PFG/Results/VALORES CONTAMINACION/MEDITERRANEO']\n",
    "output_files = [\"/Users/silviadelatorre/Desktop/TFG/PFG/Results/VALORES CONTAMINACION/ATLANTICO/ContaminacionAtlantico.csv\",\"/Users/silviadelatorre/Desktop/TFG/PFG/Results/VALORES CONTAMINACION/MEDITERRANEO/ContaminacionMediterraneo.csv\"]\n",
    "\n",
    "merged_df = merge_csv_files_in_directory(vertientes_directorios,output_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#CONCATENAR FICHEROS DE LAS VERTIENTS\n",
    "def merge_agents(directory, agent_name):\n",
    "    dfs = []\n",
    "    for vertiente in ['ATLANTICO', 'MEDITERRANEO']:\n",
    "        vertiente_path = os.path.join(directory, vertiente)\n",
    "        agent_path = os.path.join(vertiente_path, f'{agent_name}.csv')\n",
    "        if os.path.exists(agent_path):\n",
    "            df = pd.read_csv(agent_path)\n",
    "            print(f'Numero de filas {vertiente} en {agent_name} son {df.shape[0]}')\n",
    "            dfs.append(df)\n",
    "    merged_df = pd.concat(dfs)\n",
    "    return merged_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Directorio base donde se encuentran las carpetas ATLANTICO y MEDITERRANEO\n",
    "base_directory = \"/Users/silviadelatorre/Desktop/TFG/PFG/Results/VALORES CONTAMINACION\"\n",
    "\n",
    "agentes_contaminantes = ['Nitrato', 'Amonio', 'Fosforo', 'Fosfato','Fitobentos','Grado Trofico']\n",
    "contaminacion_global = pd.DataFrame()\n",
    "\n",
    "for agente in agentes_contaminantes:\n",
    "    merged_df = merge_agents(base_directory, agente)\n",
    "    output_path = os.path.join(base_directory, f'{agente}_merged.csv')\n",
    "    merged_df.to_csv(output_path, index=False)\n",
    "    print(f'Numero de filas en {agente} son {merged_df.shape[0]}')\n",
    "    if contaminacion_global.empty:\n",
    "        contaminacion_global = merged_df\n",
    "    else:\n",
    "        contaminacion_global = pd.merge(contaminacion_global, merged_df, on=['ID_RIO', 'coord_TRAMO'], how='outer')\n",
    "\n",
    "contaminacion_global.to_csv(os.path.join(base_directory, 'ContaminacionGlobal.csv'), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Calcular la suma total de contaminacion por cada rio\n",
    "contaminacion_global = pd.read_csv(\"/Users/silviadelatorre/Desktop/TFG/PFG/Results/VALORES CONTAMINACION/ContaminacionGlobal.csv\")\n",
    "contaminacion_global['Contaminación Total'] = contaminacion_global.filter(like='valor_').sum(axis=1)\n",
    "contaminacion_global.to_csv(\"/Users/silviadelatorre/Desktop/TFG/PFG/Results/VALORES CONTAMINACION/ContaminacionGlobal.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def DibujarGrafica2(Dir,rio,agente):\n",
    "    '''Grafica de los resultados'''\n",
    "\n",
    "    # Leer los datos de la tabla\n",
    "    tabla = os.path.join(Dir, f'{rio}.csv')\n",
    "    datosHeader = [\"Iteracion\",\"Tiempo Infección\",\"Nodos infectados\",\"Ratio infectados\",\"Nodos Totales\",\"pC\",\"pR\"]\n",
    "    datos = pd.read_table(tabla, engine='python', delimiter=' ', header=0, encoding = \"ISO-8859-1\", names=datosHeader)\n",
    "\n",
    "    valores_pR = [0.0, 0.1, 0.2, 0.3, 0.4]\n",
    "    for pR in valores_pR:\n",
    "        datos_pR = datos[datos['pR'] == pR]\n",
    "\n",
    "        # Crear una nueva figura para cada valor de pR\n",
    "        fig = plt.figure()\n",
    "\n",
    "        # Iterar sobre cada valor de pC y graficar la línea correspondiente\n",
    "        datos_agrupados = datos_pR.groupby('pC')['Tiempo Infección'].mean().reset_index()\n",
    "\n",
    "        # Paso 3: Generar la Gráfica\n",
    "        plt.plot(datos_agrupados['pC'], datos_agrupados['Tiempo Infección'], marker='o', linestyle='-')\n",
    "        plt.title(f'Mar contaminado de {agente} dado la Probabilidad de Recuperación {pR} en {rio}')\n",
    "        plt.xlabel('Probabilidad de Contagio (pC)')\n",
    "        plt.ylabel('Tiempo de Infección Promedio')\n",
    "\n",
    "        mi_path=os.path.join(Dir, f'pContagio_{rio}_{pR}.png')\n",
    "    \n",
    "        plt.legend()\n",
    "        \n",
    "        fig.savefig(mi_path)\n",
    "    plt.close(fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#NUMERO DE SENSORES\n",
    "sensores = [\"/Users/silviadelatorre/Desktop/TFG/PFG/Data/AGENTES CONTAMINANTES/Amonio.csv\",\"/Users/silviadelatorre/Desktop/TFG/PFG/Data/AGENTES CONTAMINANTES/Fitobentos.csv\",\"/Users/silviadelatorre/Desktop/TFG/PFG/Data/AGENTES CONTAMINANTES/Fosfato.csv\",\"/Users/silviadelatorre/Desktop/TFG/PFG/Data/AGENTES CONTAMINANTES/Fosforo.csv\",\"/Users/silviadelatorre/Desktop/TFG/PFG/Data/AGENTES CONTAMINANTES/Nitratos.csv\",\"/Users/silviadelatorre/Desktop/TFG/PFG/Data/AGENTES CONTAMINANTES/Grafo_Trofico.csv\"]\n",
    "for sensor in sensores:\n",
    "    df = pd.read_csv(sensor)\n",
    "    print(f'Numero de sensores en {sensor} son {df.shape[0]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "agentes_merged = [\"/Users/silviadelatorre/Desktop/TFG/PFG/Results/VALORES CONTAMINACION/Amonio_merged.csv\", \"/Users/silviadelatorre/Desktop/TFG/PFG/Results/VALORES CONTAMINACION/Fitobentos_merged.csv\", \"/Users/silviadelatorre/Desktop/TFG/PFG/Results/VALORES CONTAMINACION/Fosfato_merged.csv\", \"/Users/silviadelatorre/Desktop/TFG/PFG/Results/VALORES CONTAMINACION/Fosforo_merged.csv\", \"/Users/silviadelatorre/Desktop/TFG/PFG/Results/VALORES CONTAMINACION/Grado Trofico_merged.csv\", \"/Users/silviadelatorre/Desktop/TFG/PFG/Results/VALORES CONTAMINACION/Nitrato_merged.csv\"]\n",
    "\n",
    "for agente in agentes_merged:\n",
    "    df = pd.read_csv(agente)\n",
    "    print(f'Numero de filas en {agente} son {df.shape[0]}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
